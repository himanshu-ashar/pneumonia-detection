{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Densenet_with_aug.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1Y_C7uKt4XP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f65afc40-037e-41ed-a756-5ec8c1f73df1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ04mduyu5AO"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model, Sequential, save_model, model_from_json, load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import callbacks\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiU22wVL-KZJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b1995fa5-7bbf-4501-e015-61a01666ef28"
      },
      "source": [
        "print(\"Training set:\")\n",
        "for content in os.listdir(\"/content/drive/My Drive/pneumonia-detection1/train/\"):\n",
        "    print(str(len(os.listdir(\"/content/drive/My Drive/pneumonia-detection1/train/\"+content))),content,\"images.\")\n",
        "\n",
        "print(\"Validation set:\")\n",
        "for content in os.listdir(\"/content/drive/My Drive/pneumonia-detection1/validation/\"):\n",
        "    print(str(len(os.listdir(\"/content/drive/My Drive/pneumonia-detection1/validation/\"+content))),content,\"images.\")\n",
        "\n",
        "print(\"Test set:\")\n",
        "for content in os.listdir(\"/content/drive/My Drive/pneumonia-detection1/test/\"):\n",
        "    print(str(len(os.listdir(\"/content/drive/My Drive/pneumonia-detection1/test/\"+content))),content,\"images.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set:\n",
            "1199 Normal images.\n",
            "2289 Bacterial Pneumonia images.\n",
            "1196 Viral Pneumonia images.\n",
            "Validation set:\n",
            "251 Bacterial Pneumonia images.\n",
            "150 Normal images.\n",
            "151 Viral Pneumonia images.\n",
            "Test set:\n",
            "243 Bacterial Pneumonia images.\n",
            "234 Normal images.\n",
            "149 Viral Pneuomina images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4D-cfTWHM7l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4771742c-6e69-49e2-df21-144c91c94c37"
      },
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "                                    rescale=1./255,\n",
        "                                    rotation_range=30,\n",
        "                                    zoom_range=0.15,\n",
        "                                    shear_range=0.15,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode=\"nearest\"\n",
        "                                    )\n",
        "#data_generat = ImageDataGenerator(rescale=1./255)\n",
        "train_gen = data_generator.flow_from_directory(\"/content/drive/My Drive/pneumonia-detection1/train\",\n",
        "                                               target_size=(256,256),\n",
        "                                               color_mode='rgb',\n",
        "                                               class_mode=\"categorical\",\n",
        "                                               batch_size=16,\n",
        "                                               shuffle=True)\n",
        "\n",
        "val_gen = data_generator.flow_from_directory(\"/content/drive/My Drive/pneumonia-detection1/validation\",\n",
        "                                               target_size=(256,256),\n",
        "                                               color_mode='rgb',\n",
        "                                               class_mode=\"categorical\",\n",
        "                                               batch_size=16,\n",
        "                                               )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4682 images belonging to 3 classes.\n",
            "Found 550 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSOjtBXcIBNV"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thXHJIO2tVb_"
      },
      "source": [
        "Model **1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVOgTy0aQJ2Q"
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfnxDYYG18Ba"
      },
      "source": [
        "# r = model.fit(train_gen,epochs=25,validation_data=val_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_y1x37n1xBx"
      },
      "source": [
        "# model.save('/content/drive/My Drive/pneumonia-detection/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqD1Ip1Qtdad"
      },
      "source": [
        "Model **2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7MEV4vJxFum",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "82cb243e-2d2e-4f3c-a02e-b0794c2192ed"
      },
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "resnet = tf.keras.applications.DenseNet169(input_shape=(256,256,3), weights='imagenet', include_top=False)\n",
        "x = Flatten()(resnet.output)\n",
        "x = Dense(512 ,activation='relu')(x)\n",
        "x = Dense(64 ,activation='relu')(x)\n",
        "prediction = Dense(3 ,activation='softmax')(x),\n",
        "model = Model(inputs=resnet.input, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i0yheRUbzsJ"
      },
      "source": [
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzxvSKHq417Q"
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jGLg1175AT3"
      },
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXoTKadxKlkL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ebac32c6-04f0-4608-e058-520ccd9c9ee2"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/pnuemonia-detection1/dense_net_models/model{epoch:02d}.h5', save_weights_only=True, monitor='accuracy', verbose=1,\n",
        "    save_best_only=False, mode='auto', period=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFMBcuI9Span"
      },
      "source": [
        "class CustomSaver(callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if epoch==0 or epoch==19 or epoch==39 or epoch==49 or epoch==59 or epoch==69 or epoch==79 or epoch==89 or epoch==99:\n",
        "      self.model.save(\"/content/drive/My Drive/pneumonia-detection1/dense_net_models/model_epoch_{}_loss_{:7.2f}.h5\".format(epoch, logs['loss']))\n",
        "      print(\"Epoch {} over. Saving model\".format(epoch))\n",
        "\n",
        "model_saver = CustomSaver()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URGjqyWfLKob",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "231eb25a-e465-4d81-cff9-065ed5a2f34d"
      },
      "source": [
        "r = model.fit(\n",
        "  train_gen,\n",
        "  validation_data=val_gen,\n",
        "  epochs=100,\n",
        "  callbacks = [model_saver]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "293/293 [==============================] - ETA: 0s - loss: 0.7532 - accuracy: 0.7407Epoch 0 over. Saving model\n",
            "293/293 [==============================] - 135s 461ms/step - loss: 0.7532 - accuracy: 0.7407 - val_loss: 0.4902 - val_accuracy: 0.7855\n",
            "Epoch 2/100\n",
            "293/293 [==============================] - 133s 454ms/step - loss: 0.5049 - accuracy: 0.7828 - val_loss: 0.4512 - val_accuracy: 0.8164\n",
            "Epoch 3/100\n",
            "293/293 [==============================] - 131s 448ms/step - loss: 0.4876 - accuracy: 0.7864 - val_loss: 0.4656 - val_accuracy: 0.8018\n",
            "Epoch 4/100\n",
            "293/293 [==============================] - 132s 449ms/step - loss: 0.4638 - accuracy: 0.7943 - val_loss: 0.4640 - val_accuracy: 0.8182\n",
            "Epoch 5/100\n",
            "293/293 [==============================] - 131s 447ms/step - loss: 0.4726 - accuracy: 0.7930 - val_loss: 0.4216 - val_accuracy: 0.8255\n",
            "Epoch 6/100\n",
            "293/293 [==============================] - 132s 450ms/step - loss: 0.4648 - accuracy: 0.7939 - val_loss: 0.5800 - val_accuracy: 0.7309\n",
            "Epoch 7/100\n",
            "293/293 [==============================] - 129s 441ms/step - loss: 0.4535 - accuracy: 0.7973 - val_loss: 0.4507 - val_accuracy: 0.8091\n",
            "Epoch 8/100\n",
            "293/293 [==============================] - 130s 445ms/step - loss: 0.4355 - accuracy: 0.8116 - val_loss: 0.4224 - val_accuracy: 0.8455\n",
            "Epoch 9/100\n",
            "293/293 [==============================] - 131s 448ms/step - loss: 0.4337 - accuracy: 0.8041 - val_loss: 0.4511 - val_accuracy: 0.8218\n",
            "Epoch 10/100\n",
            "293/293 [==============================] - 130s 443ms/step - loss: 0.4299 - accuracy: 0.8174 - val_loss: 0.4046 - val_accuracy: 0.8545\n",
            "Epoch 11/100\n",
            "293/293 [==============================] - 128s 437ms/step - loss: 0.4245 - accuracy: 0.8163 - val_loss: 0.4080 - val_accuracy: 0.8218\n",
            "Epoch 12/100\n",
            "293/293 [==============================] - 126s 430ms/step - loss: 0.4168 - accuracy: 0.8193 - val_loss: 0.4544 - val_accuracy: 0.8145\n",
            "Epoch 13/100\n",
            "293/293 [==============================] - 126s 429ms/step - loss: 0.4158 - accuracy: 0.8095 - val_loss: 0.4412 - val_accuracy: 0.8273\n",
            "Epoch 14/100\n",
            "293/293 [==============================] - 126s 429ms/step - loss: 0.4003 - accuracy: 0.8185 - val_loss: 0.4073 - val_accuracy: 0.8527\n",
            "Epoch 15/100\n",
            "293/293 [==============================] - 126s 431ms/step - loss: 0.4059 - accuracy: 0.8206 - val_loss: 0.3772 - val_accuracy: 0.8364\n",
            "Epoch 16/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.3983 - accuracy: 0.8238 - val_loss: 0.5177 - val_accuracy: 0.8109\n",
            "Epoch 17/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.3952 - accuracy: 0.8234 - val_loss: 0.4396 - val_accuracy: 0.8109\n",
            "Epoch 18/100\n",
            "293/293 [==============================] - 126s 429ms/step - loss: 0.3931 - accuracy: 0.8308 - val_loss: 0.4340 - val_accuracy: 0.8164\n",
            "Epoch 19/100\n",
            "293/293 [==============================] - 127s 432ms/step - loss: 0.3896 - accuracy: 0.8270 - val_loss: 0.4158 - val_accuracy: 0.8418\n",
            "Epoch 20/100\n",
            "293/293 [==============================] - ETA: 0s - loss: 0.3969 - accuracy: 0.8221Epoch 19 over. Saving model\n",
            "293/293 [==============================] - 133s 453ms/step - loss: 0.3969 - accuracy: 0.8221 - val_loss: 0.4364 - val_accuracy: 0.8309\n",
            "Epoch 21/100\n",
            "293/293 [==============================] - 129s 441ms/step - loss: 0.3754 - accuracy: 0.8340 - val_loss: 0.6245 - val_accuracy: 0.7836\n",
            "Epoch 22/100\n",
            "293/293 [==============================] - 133s 452ms/step - loss: 0.3709 - accuracy: 0.8315 - val_loss: 0.4454 - val_accuracy: 0.8182\n",
            "Epoch 23/100\n",
            "293/293 [==============================] - 126s 429ms/step - loss: 0.3828 - accuracy: 0.8317 - val_loss: 0.5331 - val_accuracy: 0.8091\n",
            "Epoch 24/100\n",
            "293/293 [==============================] - 127s 434ms/step - loss: 0.3765 - accuracy: 0.8355 - val_loss: 0.5948 - val_accuracy: 0.7891\n",
            "Epoch 25/100\n",
            "293/293 [==============================] - 127s 432ms/step - loss: 0.3796 - accuracy: 0.8364 - val_loss: 0.4681 - val_accuracy: 0.7982\n",
            "Epoch 26/100\n",
            "293/293 [==============================] - 128s 436ms/step - loss: 0.3747 - accuracy: 0.8379 - val_loss: 0.4541 - val_accuracy: 0.8145\n",
            "Epoch 27/100\n",
            "293/293 [==============================] - 125s 427ms/step - loss: 0.3742 - accuracy: 0.8372 - val_loss: 0.4305 - val_accuracy: 0.8145\n",
            "Epoch 28/100\n",
            "293/293 [==============================] - 126s 431ms/step - loss: 0.3619 - accuracy: 0.8439 - val_loss: 0.4945 - val_accuracy: 0.8018\n",
            "Epoch 29/100\n",
            "293/293 [==============================] - 127s 434ms/step - loss: 0.3500 - accuracy: 0.8449 - val_loss: 0.4401 - val_accuracy: 0.8309\n",
            "Epoch 30/100\n",
            "293/293 [==============================] - 127s 434ms/step - loss: 0.3595 - accuracy: 0.8437 - val_loss: 0.3926 - val_accuracy: 0.8509\n",
            "Epoch 31/100\n",
            "293/293 [==============================] - 126s 432ms/step - loss: 0.3565 - accuracy: 0.8413 - val_loss: 0.4202 - val_accuracy: 0.8236\n",
            "Epoch 32/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.3518 - accuracy: 0.8486 - val_loss: 0.4544 - val_accuracy: 0.8164\n",
            "Epoch 33/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.3514 - accuracy: 0.8479 - val_loss: 0.3970 - val_accuracy: 0.8400\n",
            "Epoch 34/100\n",
            "293/293 [==============================] - 125s 425ms/step - loss: 0.3458 - accuracy: 0.8469 - val_loss: 0.4882 - val_accuracy: 0.8145\n",
            "Epoch 35/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.3416 - accuracy: 0.8528 - val_loss: 0.4360 - val_accuracy: 0.8364\n",
            "Epoch 36/100\n",
            "293/293 [==============================] - 123s 421ms/step - loss: 0.3447 - accuracy: 0.8490 - val_loss: 0.4156 - val_accuracy: 0.8218\n",
            "Epoch 37/100\n",
            "293/293 [==============================] - 123s 421ms/step - loss: 0.3501 - accuracy: 0.8441 - val_loss: 0.5805 - val_accuracy: 0.7782\n",
            "Epoch 38/100\n",
            "293/293 [==============================] - 125s 427ms/step - loss: 0.3537 - accuracy: 0.8509 - val_loss: 0.4951 - val_accuracy: 0.8091\n",
            "Epoch 39/100\n",
            "293/293 [==============================] - 123s 420ms/step - loss: 0.3325 - accuracy: 0.8595 - val_loss: 0.4581 - val_accuracy: 0.8218\n",
            "Epoch 40/100\n",
            "293/293 [==============================] - ETA: 0s - loss: 0.3409 - accuracy: 0.8578Epoch 39 over. Saving model\n",
            "293/293 [==============================] - 127s 434ms/step - loss: 0.3409 - accuracy: 0.8578 - val_loss: 0.4436 - val_accuracy: 0.8382\n",
            "Epoch 41/100\n",
            "293/293 [==============================] - 125s 428ms/step - loss: 0.3386 - accuracy: 0.8528 - val_loss: 0.4128 - val_accuracy: 0.8382\n",
            "Epoch 42/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.3453 - accuracy: 0.8511 - val_loss: 0.4350 - val_accuracy: 0.8200\n",
            "Epoch 43/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.3257 - accuracy: 0.8565 - val_loss: 0.4234 - val_accuracy: 0.8200\n",
            "Epoch 44/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.3323 - accuracy: 0.8535 - val_loss: 0.5304 - val_accuracy: 0.8036\n",
            "Epoch 45/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.3462 - accuracy: 0.8526 - val_loss: 0.4738 - val_accuracy: 0.8091\n",
            "Epoch 46/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.3354 - accuracy: 0.8496 - val_loss: 0.4340 - val_accuracy: 0.8218\n",
            "Epoch 47/100\n",
            "293/293 [==============================] - 123s 420ms/step - loss: 0.3365 - accuracy: 0.8522 - val_loss: 0.4952 - val_accuracy: 0.8145\n",
            "Epoch 48/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.3285 - accuracy: 0.8622 - val_loss: 0.4282 - val_accuracy: 0.8091\n",
            "Epoch 49/100\n",
            "293/293 [==============================] - 123s 421ms/step - loss: 0.3130 - accuracy: 0.8680 - val_loss: 0.4090 - val_accuracy: 0.8273\n",
            "Epoch 50/100\n",
            "293/293 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.8631Epoch 49 over. Saving model\n",
            "293/293 [==============================] - 128s 435ms/step - loss: 0.3169 - accuracy: 0.8631 - val_loss: 0.4487 - val_accuracy: 0.8164\n",
            "Epoch 51/100\n",
            "293/293 [==============================] - 125s 428ms/step - loss: 0.3241 - accuracy: 0.8637 - val_loss: 0.5994 - val_accuracy: 0.7927\n",
            "Epoch 52/100\n",
            "293/293 [==============================] - 123s 421ms/step - loss: 0.3311 - accuracy: 0.8573 - val_loss: 0.4472 - val_accuracy: 0.8327\n",
            "Epoch 53/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.3158 - accuracy: 0.8652 - val_loss: 0.4468 - val_accuracy: 0.8345\n",
            "Epoch 54/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.3069 - accuracy: 0.8657 - val_loss: 0.4697 - val_accuracy: 0.8145\n",
            "Epoch 55/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.3183 - accuracy: 0.8605 - val_loss: 0.4269 - val_accuracy: 0.8382\n",
            "Epoch 56/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.3127 - accuracy: 0.8635 - val_loss: 0.4290 - val_accuracy: 0.8091\n",
            "Epoch 57/100\n",
            "293/293 [==============================] - 123s 421ms/step - loss: 0.3139 - accuracy: 0.8635 - val_loss: 0.5979 - val_accuracy: 0.7673\n",
            "Epoch 58/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.3059 - accuracy: 0.8652 - val_loss: 0.4403 - val_accuracy: 0.8073\n",
            "Epoch 59/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.3086 - accuracy: 0.8704 - val_loss: 0.5039 - val_accuracy: 0.7945\n",
            "Epoch 60/100\n",
            "293/293 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.8648Epoch 59 over. Saving model\n",
            "293/293 [==============================] - 128s 436ms/step - loss: 0.3084 - accuracy: 0.8648 - val_loss: 0.4262 - val_accuracy: 0.8400\n",
            "Epoch 61/100\n",
            "293/293 [==============================] - 125s 426ms/step - loss: 0.2962 - accuracy: 0.8714 - val_loss: 0.5346 - val_accuracy: 0.7927\n",
            "Epoch 62/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.3062 - accuracy: 0.8659 - val_loss: 0.4678 - val_accuracy: 0.8000\n",
            "Epoch 63/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.3026 - accuracy: 0.8736 - val_loss: 0.4620 - val_accuracy: 0.8309\n",
            "Epoch 64/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.3003 - accuracy: 0.8727 - val_loss: 0.7018 - val_accuracy: 0.7673\n",
            "Epoch 65/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.3005 - accuracy: 0.8691 - val_loss: 0.5453 - val_accuracy: 0.8127\n",
            "Epoch 66/100\n",
            "293/293 [==============================] - 123s 421ms/step - loss: 0.3062 - accuracy: 0.8757 - val_loss: 0.4181 - val_accuracy: 0.8255\n",
            "Epoch 67/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.2992 - accuracy: 0.8682 - val_loss: 0.4271 - val_accuracy: 0.8345\n",
            "Epoch 68/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.2988 - accuracy: 0.8723 - val_loss: 0.4754 - val_accuracy: 0.7855\n",
            "Epoch 69/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.3031 - accuracy: 0.8716 - val_loss: 0.5944 - val_accuracy: 0.7855\n",
            "Epoch 70/100\n",
            "293/293 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.8727Epoch 69 over. Saving model\n",
            "293/293 [==============================] - 128s 436ms/step - loss: 0.3042 - accuracy: 0.8727 - val_loss: 0.4150 - val_accuracy: 0.8400\n",
            "Epoch 71/100\n",
            "293/293 [==============================] - 126s 429ms/step - loss: 0.2899 - accuracy: 0.8742 - val_loss: 0.4511 - val_accuracy: 0.8255\n",
            "Epoch 72/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.2960 - accuracy: 0.8736 - val_loss: 0.4394 - val_accuracy: 0.8236\n",
            "Epoch 73/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.3073 - accuracy: 0.8657 - val_loss: 0.4551 - val_accuracy: 0.8236\n",
            "Epoch 74/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.2841 - accuracy: 0.8804 - val_loss: 0.4874 - val_accuracy: 0.8236\n",
            "Epoch 75/100\n",
            "293/293 [==============================] - 124s 425ms/step - loss: 0.2962 - accuracy: 0.8744 - val_loss: 0.3917 - val_accuracy: 0.8273\n",
            "Epoch 76/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.2807 - accuracy: 0.8774 - val_loss: 0.4242 - val_accuracy: 0.8200\n",
            "Epoch 77/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.2934 - accuracy: 0.8806 - val_loss: 0.4594 - val_accuracy: 0.8145\n",
            "Epoch 78/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.2824 - accuracy: 0.8778 - val_loss: 0.4904 - val_accuracy: 0.8018\n",
            "Epoch 79/100\n",
            "293/293 [==============================] - 123s 421ms/step - loss: 0.2911 - accuracy: 0.8778 - val_loss: 0.4134 - val_accuracy: 0.8309\n",
            "Epoch 80/100\n",
            "293/293 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.8840Epoch 79 over. Saving model\n",
            "293/293 [==============================] - 127s 434ms/step - loss: 0.2911 - accuracy: 0.8840 - val_loss: 0.4680 - val_accuracy: 0.8000\n",
            "Epoch 81/100\n",
            "293/293 [==============================] - 125s 426ms/step - loss: 0.2894 - accuracy: 0.8759 - val_loss: 0.4551 - val_accuracy: 0.8200\n",
            "Epoch 82/100\n",
            "293/293 [==============================] - 125s 425ms/step - loss: 0.2816 - accuracy: 0.8783 - val_loss: 0.4115 - val_accuracy: 0.8236\n",
            "Epoch 83/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.2753 - accuracy: 0.8812 - val_loss: 0.6841 - val_accuracy: 0.7709\n",
            "Epoch 84/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.2865 - accuracy: 0.8780 - val_loss: 0.4093 - val_accuracy: 0.8218\n",
            "Epoch 85/100\n",
            "293/293 [==============================] - 125s 426ms/step - loss: 0.2860 - accuracy: 0.8772 - val_loss: 0.5150 - val_accuracy: 0.8145\n",
            "Epoch 86/100\n",
            "293/293 [==============================] - 124s 423ms/step - loss: 0.2921 - accuracy: 0.8768 - val_loss: 0.5404 - val_accuracy: 0.8164\n",
            "Epoch 87/100\n",
            "293/293 [==============================] - 124s 425ms/step - loss: 0.2789 - accuracy: 0.8785 - val_loss: 0.6226 - val_accuracy: 0.7636\n",
            "Epoch 88/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.2846 - accuracy: 0.8789 - val_loss: 0.5101 - val_accuracy: 0.8055\n",
            "Epoch 89/100\n",
            "293/293 [==============================] - 124s 422ms/step - loss: 0.2917 - accuracy: 0.8795 - val_loss: 0.4873 - val_accuracy: 0.8182\n",
            "Epoch 90/100\n",
            "293/293 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.8729Epoch 89 over. Saving model\n",
            "293/293 [==============================] - 128s 437ms/step - loss: 0.2945 - accuracy: 0.8729 - val_loss: 0.4561 - val_accuracy: 0.8236\n",
            "Epoch 91/100\n",
            "293/293 [==============================] - 125s 428ms/step - loss: 0.2768 - accuracy: 0.8795 - val_loss: 0.4665 - val_accuracy: 0.8218\n",
            "Epoch 92/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.2808 - accuracy: 0.8819 - val_loss: 0.4669 - val_accuracy: 0.8273\n",
            "Epoch 93/100\n",
            "293/293 [==============================] - 125s 426ms/step - loss: 0.2687 - accuracy: 0.8868 - val_loss: 0.4864 - val_accuracy: 0.8073\n",
            "Epoch 94/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.2832 - accuracy: 0.8738 - val_loss: 0.4573 - val_accuracy: 0.8127\n",
            "Epoch 95/100\n",
            "293/293 [==============================] - 125s 426ms/step - loss: 0.2793 - accuracy: 0.8789 - val_loss: 0.5049 - val_accuracy: 0.8091\n",
            "Epoch 96/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.2706 - accuracy: 0.8859 - val_loss: 0.5002 - val_accuracy: 0.8091\n",
            "Epoch 97/100\n",
            "293/293 [==============================] - 124s 424ms/step - loss: 0.2675 - accuracy: 0.8881 - val_loss: 0.4969 - val_accuracy: 0.8182\n",
            "Epoch 98/100\n",
            "293/293 [==============================] - 125s 426ms/step - loss: 0.2726 - accuracy: 0.8853 - val_loss: 0.4226 - val_accuracy: 0.8164\n",
            "Epoch 99/100\n",
            "293/293 [==============================] - 126s 431ms/step - loss: 0.2728 - accuracy: 0.8815 - val_loss: 0.4290 - val_accuracy: 0.8236\n",
            "Epoch 100/100\n",
            "293/293 [==============================] - ETA: 0s - loss: 0.2646 - accuracy: 0.8862Epoch 99 over. Saving model\n",
            "293/293 [==============================] - 131s 449ms/step - loss: 0.2646 - accuracy: 0.8862 - val_loss: 0.4409 - val_accuracy: 0.8127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHZ8kPTp5Yt7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "5df29de9-5fa1-4b1f-e666-93cb85f484ba"
      },
      "source": [
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmbClntY5ey8"
      },
      "source": [
        "model.save('/content/drive/My Drive/pneumonia-detection/models/model_resnet101.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im9kzLka_rja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "160cd15a-7116-4833-d26b-64327b92db62"
      },
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "densenet = tf.keras.applications.DenseNet201(input_shape=(256,256,3), weights='imagenet', include_top=False)\n",
        "x = Flatten()(resnet.output)\n",
        "x = Dense(512 ,activation='relu')(x)\n",
        "x = Dense(64 ,activation='relu')(x)\n",
        "prediction = Dense(3 ,activation='softmax')(x),\n",
        "model1 = Model(inputs=resnet.input, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-f8d1a69e8ac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# Model must be created under scope of DistStrat it will be trained with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m    172\u001b[0m       \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 307\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1793\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_6:0\", shape=(None, 299, 299, 3), dtype=float32) at layer \"input_6\". The following previous layers were accessed without issue: []"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSE2U8izGwyY"
      },
      "source": [
        "for layer in densenet.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCwJl8hKGQ1C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6fa42721-32e2-4d1e-bd89-73640601ec4d"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 16, 16, 256)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_relu (Activation (None, 16, 16, 256)  0           conv4_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_add (Add)          (None, 16, 16, 1024) 0           conv4_block6_out[0][0]           \n",
            "                                                                 conv4_block7_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_out (Activation)   (None, 16, 16, 1024) 0           conv4_block7_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 16, 16, 256)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_relu (Activation (None, 16, 16, 256)  0           conv4_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_add (Add)          (None, 16, 16, 1024) 0           conv4_block7_out[0][0]           \n",
            "                                                                 conv4_block8_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_out (Activation)   (None, 16, 16, 1024) 0           conv4_block8_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 16, 16, 256)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_relu (Activation (None, 16, 16, 256)  0           conv4_block9_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_add (Add)          (None, 16, 16, 1024) 0           conv4_block8_out[0][0]           \n",
            "                                                                 conv4_block9_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_out (Activation)   (None, 16, 16, 1024) 0           conv4_block9_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block9_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_add (Add)         (None, 16, 16, 1024) 0           conv4_block9_out[0][0]           \n",
            "                                                                 conv4_block10_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_out (Activation)  (None, 16, 16, 1024) 0           conv4_block10_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block10_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_add (Add)         (None, 16, 16, 1024) 0           conv4_block10_out[0][0]          \n",
            "                                                                 conv4_block11_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_out (Activation)  (None, 16, 16, 1024) 0           conv4_block11_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block11_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_add (Add)         (None, 16, 16, 1024) 0           conv4_block11_out[0][0]          \n",
            "                                                                 conv4_block12_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_out (Activation)  (None, 16, 16, 1024) 0           conv4_block12_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block12_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_add (Add)         (None, 16, 16, 1024) 0           conv4_block12_out[0][0]          \n",
            "                                                                 conv4_block13_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_out (Activation)  (None, 16, 16, 1024) 0           conv4_block13_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block13_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_add (Add)         (None, 16, 16, 1024) 0           conv4_block13_out[0][0]          \n",
            "                                                                 conv4_block14_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_out (Activation)  (None, 16, 16, 1024) 0           conv4_block14_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block14_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_add (Add)         (None, 16, 16, 1024) 0           conv4_block14_out[0][0]          \n",
            "                                                                 conv4_block15_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_out (Activation)  (None, 16, 16, 1024) 0           conv4_block15_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block15_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_add (Add)         (None, 16, 16, 1024) 0           conv4_block15_out[0][0]          \n",
            "                                                                 conv4_block16_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_out (Activation)  (None, 16, 16, 1024) 0           conv4_block16_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block16_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_add (Add)         (None, 16, 16, 1024) 0           conv4_block16_out[0][0]          \n",
            "                                                                 conv4_block17_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_out (Activation)  (None, 16, 16, 1024) 0           conv4_block17_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block17_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_add (Add)         (None, 16, 16, 1024) 0           conv4_block17_out[0][0]          \n",
            "                                                                 conv4_block18_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_out (Activation)  (None, 16, 16, 1024) 0           conv4_block18_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block18_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_add (Add)         (None, 16, 16, 1024) 0           conv4_block18_out[0][0]          \n",
            "                                                                 conv4_block19_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_out (Activation)  (None, 16, 16, 1024) 0           conv4_block19_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block19_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_add (Add)         (None, 16, 16, 1024) 0           conv4_block19_out[0][0]          \n",
            "                                                                 conv4_block20_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_out (Activation)  (None, 16, 16, 1024) 0           conv4_block20_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block20_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_add (Add)         (None, 16, 16, 1024) 0           conv4_block20_out[0][0]          \n",
            "                                                                 conv4_block21_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_out (Activation)  (None, 16, 16, 1024) 0           conv4_block21_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block21_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_add (Add)         (None, 16, 16, 1024) 0           conv4_block21_out[0][0]          \n",
            "                                                                 conv4_block22_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_out (Activation)  (None, 16, 16, 1024) 0           conv4_block22_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block22_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_add (Add)         (None, 16, 16, 1024) 0           conv4_block22_out[0][0]          \n",
            "                                                                 conv4_block23_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_out (Activation)  (None, 16, 16, 1024) 0           conv4_block23_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 131072)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 512)          67109376    flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 64)           32832       dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 3)            195         dense_10[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 109,800,579\n",
            "Trainable params: 67,142,403\n",
            "Non-trainable params: 42,658,176\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ5E28maHCNW"
      },
      "source": [
        "model1.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQRa-TdXGbED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "f3ed84e6-4a3d-4400-e639-44688f0ec285"
      },
      "source": [
        "r1 = model1.fit(\n",
        "  train_gen,\n",
        "  validation_data=val_gen,\n",
        "  epochs=50,\n",
        "  callbacks=checkpoint,\n",
        "  steps_per_epoch=len(train_gen),\n",
        "  validation_steps=len(val_gen)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "106/156 [===================>..........] - ETA: 49s - loss: 0.6146 - accuracy: 0.7341"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-3f19dd3f1887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3MmAV6CpQ5A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ad7af18-a02a-4bc9-bd4d-21736abb025d"
      },
      "source": [
        "test_gen = data_generator.flow_from_directory(\"/content/drive/My Drive/pneumonia-detection/test/\",\n",
        "                                               target_size=(256,256),\n",
        "                                               color_mode='rgb',\n",
        "                                               class_mode=\"categorical\",\n",
        "                                               batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWT9tqfDUlCn"
      },
      "source": [
        "model = tensorflow.keras.models.load_model('/content/drive/My Drive/pneumonia-detection/models/model_resnet101.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7yCaX0t2XaB"
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REObtHd0U5SK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f7b023f6-2cf6-43d5-8605-03d38504323f"
      },
      "source": [
        "model.evaluate(test_gen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 198s 10s/step - loss: 1.9582 - accuracy: 0.6506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.9581643342971802, 0.6506410241127014]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqIDjDfq24lg"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import SVG, Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn-Wc7RkU8O8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "4d8f0d5e-3561-4236-f754-86071eeb2d7e"
      },
      "source": [
        "plot_model(model, to_file='/content/drive/My Drive/pneumonia-detection/models/model_resnet101.png', show_shapes=True, show_layer_names=True)\n",
        "Image('model.png',width=400, height=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.869151 to fit\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "model.png",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 400,
              "height": 200
            }
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbmTFYQh20ca"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}